/**
 * IntegraÃ§Ã£o com OpenAI API usando histÃ³rico e contexto por cliente.
 * - Usa GPT-4o-mini (ajustÃ¡vel via .env)
 * - MantÃ©m histÃ³rico de mensagens
 * - LÃª contexto personalizado de bot/clientes/<clienteId>.json
 * - Adiciona logs detalhados para debug
 */

const { OpenAI } = require("openai");
const dotenv = require("dotenv");
const fs = require("fs");
const path = require("path");

const { getHistory, addMessage } = require("./history.js");
const { logger } = require("./logger.js"); // âœ… jÃ¡ corrigido com { }

dotenv.config();

const clientesDir = path.join(process.cwd(), "bot", "clientes");

async function responderComIA(sessionId, mensagem) {
  try {
    // ğŸ”¹ Cria nova instÃ¢ncia OpenAI por chamada
    const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

    // ğŸ”¹ 1. Log da mensagem recebida
    logger.info(`ğŸ¤– [${sessionId}] Mensagem recebida: ${mensagem}`);

    // ğŸ”¹ 2. LÃª o contexto do arquivo JSON do cliente (se existir)
    let contextoIA = "VocÃª Ã© um assistente Ãºtil, educado e profissional.";

    const clienteConfigPath = path.join(clientesDir, `${sessionId}.json`);
    if (fs.existsSync(clienteConfigPath)) {
      const data = JSON.parse(fs.readFileSync(clienteConfigPath));
      if (data.contextoIA) contextoIA = data.contextoIA;
    }

    logger.info(`ğŸ¤– [${sessionId}] Contexto usado: ${contextoIA}`);

    // ğŸ”¹ 3. Recupera histÃ³rico de conversa
    const history = getHistory(sessionId);
    logger.info(`ğŸ¤– [${sessionId}] HistÃ³rico atual: ${JSON.stringify(history)}`);

    const messages = [
      { role: "system", content: contextoIA },
      ...history,
      { role: "user", content: mensagem }
    ];

    // ğŸ”¹ 4. Chama a API da OpenAI
    const response = await client.chat.completions.create({
      model: process.env.OPENAI_MODEL || "gpt-4o-mini",
      messages,
      temperature: 0.7
    });

    // ğŸ”¹ 5. Processa e registra a resposta
    const resposta = response.choices[0].message.content.trim();
    addMessage(sessionId, "user", mensagem);
    addMessage(sessionId, "assistant", resposta);

    logger.info(`ğŸ¤– [${sessionId}] IA respondeu: ${resposta}`);
    return resposta;

  } catch (error) {
    // ğŸ”¹ Log detalhado do erro
    logger.error(`âŒ Erro ao gerar resposta com IA para ${sessionId}: ${error.message}`);
    logger.error(error.stack); // Stack trace completo
    return "Desculpe, ocorreu um erro ao processar sua mensagem.";
  }
}

module.exports = { responderComIA };
